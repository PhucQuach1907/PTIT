{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccc620f1-b27d-4722-be9b-bdf13c07fc74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 4, 8)              400       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 433 (1.69 KB)\n",
      "Trainable params: 433 (1.69 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "(50, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "# Define 10 restaurant reviews\n",
    "reviews = [\n",
    "    'Never coming back!',\n",
    "    'horrible service',\n",
    "    'rude waitress',\n",
    "    'cold food',\n",
    "    'horrible food!',\n",
    "    'awesome',\n",
    "    'awesome services!',\n",
    "    'rocks',\n",
    "    'poor work',\n",
    "    \"couldn't have done better\"\n",
    "]\n",
    "\n",
    "# Define labels\n",
    "labels = np.array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n",
    "\n",
    "# Create a tokenizer\n",
    "tokenizer = Tokenizer(num_words=50)\n",
    "tokenizer.fit_on_texts(reviews)\n",
    "\n",
    "# Convert text to sequences\n",
    "sequences = tokenizer.texts_to_sequences(reviews)\n",
    "\n",
    "# Pad sequences\n",
    "max_length = 4\n",
    "padded_reviews = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=50, output_dim=8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "# Print model summary\n",
    "print(model.summary())\n",
    "\n",
    "# Train the model\n",
    "model.fit(padded_reviews, labels, epochs=100, verbose=0)\n",
    "\n",
    "# Check the shape of the embedding weights\n",
    "print(model.layers[0].get_weights()[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a81436cc-6226-4897-b1c0-587144836d57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Embedding, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d964992-9eb1-444c-9933-4794ce4156b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define 10 restaurant reviews\n",
    "reviews =[\n",
    "          'Never coming back!',\n",
    "          'horrible service',\n",
    "          'rude waitress',\n",
    "          'cold food',\n",
    "          'horrible food!',\n",
    "          'awesome',\n",
    "          'awesome services!',\n",
    "          'rocks',\n",
    "          'poor work',\n",
    "          'couldn\\'t have done better'\n",
    "]\n",
    "#Define labels\n",
    "labels = array([0,0,0,1,0,1,1,1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32b0b43f-7cac-4775-9f7f-c7c38d49f1c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_and_pad(docs, vocab_size=50):\n",
    "    tokenized_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "    max_len = max([len(doc) for doc in tokenized_docs])\n",
    "    padded_docs = pad_sequences(tokenized_docs, maxlen=max_len, padding='post')\n",
    "\n",
    "    return padded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1d5914c-5e47-48cd-97bf-4fe6b3fa9ca2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = 50\n",
    "X = tokenize_and_pad(reviews, vocab_size)\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd8374da-a16a-4014-91f8-fe1fe3f1bbc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 4, 8)              400       \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 433 (1.69 KB)\n",
      "Trainable params: 433 (1.69 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Embedding(vocab_size, 8, input_length=X.shape[-1]))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(model1.summary())\n",
    "\n",
    "model1.fit(X, y, epochs=20, verbose=0)\n",
    "\n",
    "loss, accuracy = model1.evaluate(X, y, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4519625c-6672-4076-9ea0-9594416685b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 4, 8)              400       \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 466 (1.82 KB)\n",
      "Trainable params: 466 (1.82 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(vocab_size, 8, input_length=X.shape[-1]))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model2.summary())\n",
    "\n",
    "model2.fit(X, y, epochs=20, verbose=0)\n",
    "\n",
    "loss, accuracy = model2.evaluate(X, y, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a43e5a6-ad50-475d-94cd-51d86be7e98c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 4, 8)              400       \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 542 (2.12 KB)\n",
      "Trainable params: 542 (2.12 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Embedding(vocab_size, 8, input_length=X.shape[-1]))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(4, activation='relu'))\n",
    "model3.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model3.summary())\n",
    "\n",
    "model3.fit(X, y, epochs=20, verbose=0)\n",
    "\n",
    "loss, accuracy = model3.evaluate(X, y, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db38cd2-3598-4551-8fc0-2af92a9e377a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
