{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dcb1559-71bb-44e0-9ac3-7bb69574a898",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "tf.placeholder() is not compatible with eager execution.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m test_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray([\u001b[38;5;241m1.84\u001b[39m, \u001b[38;5;241m2.273\u001b[39m, \u001b[38;5;241m3.2\u001b[39m, \u001b[38;5;241m2.831\u001b[39m, \u001b[38;5;241m2.92\u001b[39m, \u001b[38;5;241m3.24\u001b[39m, \u001b[38;5;241m1.35\u001b[39m, \u001b[38;5;241m1.03\u001b[39m])\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Set placeholders for feature and target vectors\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m X \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mplaceholder(tf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     23\u001b[0m y \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mplaceholder(tf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Set model weights and bias\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:3169\u001b[0m, in \u001b[0;36mplaceholder\u001b[1;34m(dtype, shape, name)\u001b[0m\n\u001b[0;32m   3122\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Inserts a placeholder for a tensor that will be always fed.\u001b[39;00m\n\u001b[0;32m   3123\u001b[0m \n\u001b[0;32m   3124\u001b[0m \u001b[38;5;124;03m**Important**: This tensor will produce an error if evaluated. Its value must\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3166\u001b[0m \u001b[38;5;124;03m@end_compatibility\u001b[39;00m\n\u001b[0;32m   3167\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m-> 3169\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.placeholder() is not compatible with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3170\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager execution.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gen_array_ops\u001b[38;5;241m.\u001b[39mplaceholder(dtype\u001b[38;5;241m=\u001b[39mdtype, shape\u001b[38;5;241m=\u001b[39mshape, name\u001b[38;5;241m=\u001b[39mname)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: tf.placeholder() is not compatible with eager execution."
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n",
    "# Model Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 2000\n",
    "display_step = 200\n",
    "\n",
    "# Training Data\n",
    "train_X = np.asarray([3.3, 4.4, 5.5, 6.71, 6.93, 4.168, 9.779, 6.182, 7.59, 2.167,\n",
    "                     7.042, 10.791, 5.313, 7.997, 5.654, 9.27, 3.1])\n",
    "train_y = np.asarray([1.7, 2.76, 2.09, 3.19, 1.694, 1.573, 3.366, 2.596, 2.53, 1.221,\n",
    "                     2.827, 3.465, 1.65, 2.904, 2.42, 2.94, 1.3])\n",
    "n_samples = train_X.shape[0]\n",
    "\n",
    "# Test Data\n",
    "test_X = np.asarray([6.83, 4.668, 8.9, 7.91, 5.7, 8.7, 3.1, 2.1])\n",
    "test_y = np.asarray([1.84, 2.273, 3.2, 2.831, 2.92, 3.24, 1.35, 1.03])\n",
    "\n",
    "# Set placeholders for feature and target vectors\n",
    "X = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Set model weights and bias\n",
    "W = tf.Variable(np.random.randn(), name=\"weight\")\n",
    "b = tf.Variable(np.random.randn(), name=\"bias\")\n",
    "\n",
    "# Construct a linear model\n",
    "linear_model = W * X + b\n",
    "\n",
    "# Mean squared error\n",
    "cost = tf.reduce_sum(tf.square(linear_model - y)) / (2 * n_samples)\n",
    "\n",
    "# Gradient descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    # Load initialized variables in the current session\n",
    "    sess.run(init)\n",
    "\n",
    "    # Fit all training data\n",
    "    for epoch in range(training_epochs):\n",
    "        # Perform gradient descent step\n",
    "        sess.run(optimizer, feed_dict={X: train_X, y: train_y})\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if (epoch + 1) % display_step == 0:\n",
    "            c = sess.run(cost, feed_dict={X: train_X, y: train_y})\n",
    "            print(\"Epoch:{0:6} \\t Cost:{1:10.4} \\t W:{2:6.4} \\t b:{3:6.4}\".format(epoch + 1, c, sess.run(W), sess.run(b)))\n",
    "\n",
    "    # Print final parameter values\n",
    "    print(\"Optimization Finished!\")\n",
    "    training_cost = sess.run(cost, feed_dict={X: train_X, y: train_y})\n",
    "    print(\"Final training cost:\", training_cost, \"W:\", sess.run(W), \"b:\", sess.run(b), '\\n')\n",
    "\n",
    "    # Graphic display\n",
    "    plt.plot(train_X, train_y, 'ro', label='Original data')\n",
    "    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Testing the model\n",
    "    testing_cost = sess.run(tf.reduce_sum(tf.square(linear_model - y)) / (2 * test_X.shape[0]),\n",
    "                            feed_dict={X: test_X, y: test_y})\n",
    "    print(\"Final testing cost:\", testing_cost)\n",
    "    print(\"Absolute mean square loss difference:\", abs(training_cost - testing_cost))\n",
    "\n",
    "    # Display fitted line on test data\n",
    "    plt.plot(test_X, test_y, 'bo', label='Testing data')\n",
    "    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bf3ae5-1063-41cc-87ef-58285e0be1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
